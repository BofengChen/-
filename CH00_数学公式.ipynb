{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 数学公式"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 点到超平面的距离公式\n",
    "\n",
    "一个向量 $\\mathbf{x_1}$ 到超平面 $ \\mathbf{w}^T \\mathbf{x} + b = 0$ 的距离公式为\n",
    "\n",
    "$$d = \\frac{| \\mathbf{w}^T \\mathbf{x_1} + b|}{|| \\mathbf{w} ||}$$\n",
    "\n",
    "其中 $\\mathbf{w} = (w_1, w_2, ... ,w_n)^T$ 是超平面的法向量，b是常量,$||\\bullet||$ 是 $L_2$ 范数。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "简单证明如下：\n",
    "\n",
    "假设 $\\mathbf{x}_1$ 到 超平面的投影向量为 $\\mathbf{x}_0$， 则有 $ \\mathbf{w}^T \\mathbf{x}_0 + b = 0$ 。\n",
    "\n",
    "因为 $\\mathbf{x}_1 - \\mathbf{x}_0$ 与法向量 $\\mathbf{w}^T$ 平行，则有\n",
    "\n",
    "$$|\\mathbf{w}^T (\\mathbf{x}_1 - \\mathbf{x}_0)| = ||\\mathbf{w}|| |(\\mathbf{x}_1 - \\mathbf{x}_0)| = ||\\mathbf{w}||\\bullet d$$\n",
    "\n",
    "另一方面，\n",
    "\n",
    "$$\\mathbf{w}^T (\\mathbf{x}_1 - \\mathbf{x}_0) = \\mathbf{w}^T \\mathbf{x}_1 - \\mathbf{w}^T\\mathbf{x}_0 = \\mathbf{w}^T \\mathbf{x}_1 + b$$\n",
    "\n",
    "则点到超平面的距离 d 为\n",
    "$$d = \\frac{| \\mathbf{w}^T \\mathbf{x_1} + b|}{|| \\mathbf{w} ||}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [Hoeffding Inequality](https://blog.csdn.net/liubai01/article/details/79947975)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 线性相关和生成子空间"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "下面我们讨论如下方程\n",
    "\n",
    "$$\\mathbf{A}\\mathbf{x}=\\mathbf{b}$$\n",
    "\n",
    "的解存在性和唯一性。其中 $\\mathbf{A}\\in R^{m\\times n}$是一个已知矩阵，$\\mathbf{b}\\in R^{m}$ 是一个已知向量，$\\mathbf{x}\\in R^{n}$ 是一个我们要求解的未知向量。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "为了分析方程有多少个解，我们可以将 $\\mathbf{A}$ 的列向量看作从**原点**（元素都是零的向量）出发的不同方向，确定有多少种方法可以到达向量 $\\mathbf{b}$。在这个观点下，向量 $\\mathbf{x}$ 的每个元素表示我们应该沿着这些方向走多远，即$x_i$ 表示我们需要沿着第 i 个向量的方向走多远：\n",
    "\n",
    "$$\\mathbf{A}\\mathbf{x}=\\sum_i x_i\\mathbf{A}_{:,i}$$\n",
    "\n",
    "称这种操作为**线性组合**。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "一组向量的**生成子空间**是原始向量线性组合之后所能抵达的点的集合。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "**存在解的充分必要条件**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "确定 $\\mathbf{A}\\mathbf{x}=\\mathbf{b}$ 是否有解，相当于确定向量 $\\mathbf{b}$ 是否在 $\\mathbf{A}$ 列向量的生成子空间中。这个特殊的生成子空间被称为 $\\mathbf{A}$ 的 **列空间(column space)**或者 $\\mathbf{A}$ 的 **值域(range)**。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "为了使方程 $\\mathbf{A}\\mathbf{x}=\\mathbf{b}$ 对任意向量 $\\mathbf{b}$ 都存在解，我们要求 $\\mathbf{A}$ 的列空间构成整个 $R^m$，这样才能确保任意的 $\\mathbf{b}$ 包含在 $\\mathbf{A}$ 的列空间里，也就是说任意的 $\\mathbf{b}$ 是可达的。由$\\mathbf{A}\\in R^{m\\times n}$ 可知， $\\mathbf{A}$的列空间构成整个 $R^m$的要求等价于说 $\\mathbf{A}$ 至少应该有 m 列，也就是说 $n \\geq m$。\n",
    "\n",
    "**不等式 $n \\geq m$ 只是解存在的必要不充分条件**，因为 $n \\geq m$ 并不能保证可以构成 $R^m$ 空间，换言之，不能保证 $\\mathbf{A}$ 的列空间存在 m 个 **线性无关** 的向量。\n",
    "\n",
    "**所以存在解的充分条件就是：** 矩阵 $\\mathbf{A}$ 必须包含至少一组 m 个线性无关的向量。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "**唯一解的条件**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "如果要保证对于每一个 $\\mathbf{b}$ 至多有一个解，我们需要确保矩阵至多有 m 个列向量。\n",
    "\n",
    "综上所述，**意味着这个矩阵必须是一个**方阵**，即 $m=n$；并且所有列向量都是线性无关的。**\n",
    "\n",
    "一个列向量线性相关的方阵被称为**奇异的(singular)**。\n",
    "\n",
    "一个矩阵 $\\mathbf{A}$ 不是方阵或者是一个奇异的方阵，该方程仍然有解，但是我们不能使用矩阵逆去求解。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 迹运算"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "迹运算返回的是矩阵对角线元素的和：\n",
    "\n",
    "$$Tr(\\mathbf{A}) = \\sum_{i}\\mathbf{A}_{i,i}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "迹运算的性质：\n",
    "\n",
    "* 迹运算在转置运算下保持不变：\n",
    "$$Tr(\\mathbf{A})=Tr(\\mathbf{A}^T)$$\n",
    "\n",
    "* 迹运算在矩阵定义良好的循环乘积中保持不变：\n",
    "$$Tr(\\mathbf{A}\\mathbf{B}\\mathbf{C})=Tr(\\mathbf{C}\\mathbf{A}\\mathbf{B})=Tr(\\mathbf{B}\\mathbf{C}\\mathbf{A})$$\n",
    "更一般地，\n",
    "$$Tr\\left(\\prod_{i=1}^n\\mathbf{F}^{(i)}\\right)=Tr\\left(\\mathbf{F}^{(n)}\\prod_{i=1}^{n-1}\\mathbf{F}^{(i)}\\right)$$\n",
    "即使循环置换后矩阵乘积的矩阵形状从$m\\times m$ 变成 $n\\times n$，迹运算结果依然不变。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ML&DL常用函数"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [线性整流函数(Rectified Linear Unit, ReLU)](https://zh.wikipedia.org/wiki/%E7%BA%BF%E6%80%A7%E6%95%B4%E6%B5%81%E5%87%BD%E6%95%B0#%E5%B8%A6%E6%B3%84%E9%9C%B2%E7%BA%BF%E6%80%A7%E6%95%B4%E6%B5%81) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "函数定义：\n",
    "\n",
    "$$g(z) = \\max\\{0,z\\}$$\n",
    "\n",
    "函数图像如下图所示。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='figure/reLU.png' width='400' height='300' align='left'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "函数特点：\n",
    "\n",
    "该函数在机器学习中 $g(-z)$ 会作为最原始的损失函数，如SVM中；在深度学习中会作为激活函数，被推荐用于大多数前馈神经网络激活函数。它用于将线性变换的输出将产生非线性变换。\n",
    "\n",
    "函数非常接近于线性，可以看做具有两个线性部分的分段线性函数。因为几乎线性的性质，保留了很多以此作为激活函数的线性模型易于使用基于梯度方法进行优化的属性。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic sigmoid 函数"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们定义 **Logistic sigmoid 函数** 如下：\n",
    "\n",
    "$$ \\sigma(x) = \\frac{1}{1+e^{-x}}$$\n",
    "\n",
    "函数图像如下。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='figure/logistic-sigmoid.jpg' width='400' height='300' align='left'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Logistic sigmoid 函数特点**：\n",
    "\n",
    "1. Logistic sigmoid 函数通常用于产生 Bernoulli 分布中的参数 $\\phi$，因为它的范围是 $(0,1)$；\n",
    "\n",
    "\n",
    "2. **我们换一个视角来重新表达 sigmoid 函数时**：\n",
    "$$\\begin{split}\n",
    "&P(y=1|x) = \\frac{e^{1\\cdot x}}{e^{1\\cdot x}+e^{0\\cdot x}}=\\frac{1}{1+e^{-x}}=\\sigma(x)\\\\\n",
    "&P(y=0|x) = \\frac{e^{0\\cdot x}}{e^{1\\cdot x}+e^{0\\cdot x}}=\\frac{1}{1+e^x}=\\sigma(-x)\n",
    "\\end{split}$$\n",
    "我们会发现 sigmoid 函数可以看做服从 Bernoulli 分布的 $y=\\{0,1\\}$ 时的关于 x 的条件概率。分母的部分属于归一化部分，概率分布对应的构造函数为 $e^{yx}$, 我们可以统一表示服从Bernoulli 分布的概率函数为：\n",
    "$$P(y=y_i|x)=\\sigma\\left((2y_i-1)x\\right)$$\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "3. 逻辑回归模型中也用到了这个函数以及其逆函数(对数几率函数)：\n",
    "$$x =\\sigma^{-1}(y)= \\ln \\frac{y}{1-y}$$\n",
    "\n",
    "\n",
    "4. sigmoid 函数的导数性质：\n",
    "$$\\frac{d\\sigma}{dx}= \\sigma(1-\\sigma)$$\n",
    "\n",
    "\n",
    "5. 因为 sigmoid 函数在无穷远处有如下性质：\n",
    "$$\\begin{split}&\\sigma(x)\\rightarrow 0\\;(x\\rightarrow -\\infty)\\\\\n",
    "&\\sigma(x)\\rightarrow 1\\;(x\\rightarrow +\\infty)\\end{split}$$\n",
    "所以有 $\\frac{d\\sigma}{dx}\\rightarrow 0 \\; (|x|\\rightarrow \\infty)$\n",
    "\n",
    "\n",
    "6. 如图所示以及上述第四点关于导数在正负无穷远处为零的性质可知：\n",
    "\n",
    "    * **sigmoid 函数在变量趋于正负无穷时(实际操作中就是指取值的绝对值比较大时)会出现饱和(saturate)现象(导数等于0)，意味着函数会变得很平，并且对输入的微小改变不敏感。**\n",
    "    \n",
    "    \n",
    "    * **函数在接近 0 点附近导数值比较大，也就是对数值的变动比较敏感，而远离 0 点时会饱和性越来越强(导数越来趋向于0)，所以更适合做输出单元，当然要配合抑制饱和的代价函数来使用，并不太适合做隐藏单元的激活函数。**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Softplus 函数"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "定义 Softplus 函数如下：\n",
    "\n",
    "$$\\zeta(\\mathbf{x}) = \\ln(1+e^{x})$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Softplus 函数名来源于它是线性整流函数的平滑形式,下面是其图像。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='figure/softplus.png' width='400' height='300' align='left'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Softplus 函数特点**：\n",
    "\n",
    "1. Softplus 函数通常用于产生 正态分布的参数 $\\beta,\\alpha$，因为它的范围是 $(0,\\infty)$；\n",
    "\n",
    "\n",
    "2. Softplus 函数的导数性质：\n",
    "$$\\frac{d\\zeta}{dx}= \\sigma$$\n",
    "也就是说 Softplus 函数的导数恰好是sigmoid 函数;\n",
    "\n",
    "\n",
    "3. 由上述第二点的导数性质以及sigmoid 函数在负无穷远处趋于0，所以有\n",
    "$$\\frac{d\\zeta}{dx}\\rightarrow 0\\;(x\\rightarrow -\\infty)$$\n",
    "\n",
    "\n",
    "4. Softplus 函数在 $x\\rightarrow -\\infty$ 处有如下性质：\n",
    "$$\\begin{split}&\\zeta(x)\\rightarrow 0\\;(x\\rightarrow -\\infty)\\end{split}$$\n",
    "\n",
    "\n",
    "5. 因为：\n",
    "$$\\lim_{x\\rightarrow +\\infty}\\frac{x}{\\zeta(x)} \\overset{Lhopital}{=}\\lim_{x\\rightarrow +\\infty}\\frac{1}{\\sigma(x)}=1$$\n",
    "所以Softplus 函数在 $x\\rightarrow +\\infty$ 处有\n",
    "$$\\zeta(x)\\sim x\\;(x\\rightarrow +\\infty)$$\n",
    "也就是说，在变量趋于无穷远时 Softplus 函数等价于 $y=x$ 函数，这一点从图示上也能看出来。\n",
    "\n",
    "\n",
    "\n",
    "6. 如图所示以及上述第三点关于导数在负无穷远处为零的性质可知，**Softplus 函数在变量趋于负无穷时(实际操作中就是指取负值的绝对值比较大时)会出现饱和(saturate)现象，意味着函数会变得很平，并且对输入的微小改变不敏感。**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Softmax 函数"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "针对向量 $\\mathbf{x}$,我们定义它的**softmax 函数**如下：\n",
    "\n",
    "$$\\mathbf{y} = softmax(\\mathbf{x})$$\n",
    "\n",
    "其中\n",
    "\n",
    "$$y_i = \\frac{\\exp{(x_i)}}{\\sum_{j=1}^n \\exp{(x_i)}}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "可以很明显看出， Softmax 函数是 sigmoid 函数的扩展，相应地，可以视为定义了 Multinoulli 分布。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "softmax 函数的数值方法稳定的版本\n",
    "\n",
    "$$softmax(\\mathbf{z})_i = \\frac{e^{z_i}}{\\sum_{j=1}^n e^{z_j}}$$ \n",
    "\n",
    "其中\n",
    "\n",
    "$$\\mathbf{z} = \\mathbf{x} - \\max_k x_k$$\n",
    "\n",
    "上述的运算是广播机制,这种线性平移映射不会影响或者改变 $softmax(\\mathbf{x})$ 的输出值。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**关于饱和性质**：\n",
    "\n",
    "首先我们变换下数值稳定版本的表达式：\n",
    "\n",
    "$$\\begin{split}\n",
    "softmax(\\mathbf{z})_i &= \\frac{e^{z_i}}{\\sum_{j=1}^n e^{z_i}}\\\\\n",
    "\\\\\n",
    "&= \\frac{exp(x_i-\\max_k x_k)}{\\sum_{j=1}^n exp(x_j-\\max_k x_k)}\\\\\n",
    "\\\\\n",
    "&=\\frac{exp(x_i-\\max_k x_k)}{1+\\sum_{j\\neq k} exp(x_j-\\max_k x_k)}\n",
    "\\end{split}$$ \n",
    "\n",
    "由上式我们可知\n",
    "\n",
    "* 当 $x_i = \\max_k x_k \\; \\& \\; x_i\\gg x_j \\; (i\\neq j)$ 时, $softmax(\\mathbf{z})_i\\rightarrow 1$;\n",
    "* 当 $x_i \\neq \\max_k x_k \\; \\& \\; x_i\\ll \\max_k x_k$ 时, $softmax(\\mathbf{z})_i\\rightarrow 0$。\n",
    "\n",
    "这种饱和性质属于上面我们介绍的 sigmoid 函数饱和性质的一般化体现。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## tanh 函数"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "双曲正切函数定义为双曲正弦与双曲余弦的比值，如下：\n",
    "\n",
    "$$\\tanh(x) = \\frac{\\sinh(x)}{\\cosh(x)}=\\frac{e^x - e^{-x}}{e^x + e^{-x}}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "图像如下：\n",
    "\n",
    "\n",
    "<img src='figure/tanh.png' width='400' height='300' align='left'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "双曲正切函数的性质如下：\n",
    "\n",
    "1. $\\tanh(x)$ 是奇函数，即 $\\tanh(x)=\\tanh(-x)$;\n",
    "\n",
    "\n",
    "2. 双曲正切函数可以看做是符号函数 sign(x) 的平滑形式；\n",
    "\n",
    "\n",
    "3. $\\tanh(x)$ 函数在正负无穷远处的极限为 $+1,-1$；在零点附近近似于 $y=x$;\n",
    "\n",
    "\n",
    "4. $\\tanh(x)=2\\sigma(2x)-1$;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 数值计算\n",
    "\n",
    "部分内容来自于冯果忱主编的《数值分析(上册)》"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 范数"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Frobenius 范数"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "对于矩阵 $\\mathbf{A}$,我们定义其 Frobenius 范数为\n",
    "\n",
    "$$||\\mathbf{A}||_F = \\sqrt{\\sum_{i,j}A_{i,j}^2} = \\sqrt{Tr(\\mathbf{A}\\mathbf{A}^T)}$$\n",
    "\n",
    "类似于向量的 $L^2$ 范数。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 从属范数"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "对于任何矩阵 $\\mathbf{A}\\in R^{m\\times n}$，定义\n",
    "\n",
    "$$||\\mathbf{A}|| = \\max_{||\\mathbf{x}||=1}||\\mathbf{A}\\mathbf{x}||$$\n",
    "\n",
    "为矩阵 $\\mathbf{A}$ 的范数。如此得到的矩阵范数 $||\\cdot||$ 称为向量范数 $||\\cdot||$ 的**从属范数。**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 谱范数"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(向量)2范数**的从属范数为 \n",
    "\n",
    "$$||\\mathbf{A}||_2 = \\max_{||\\mathbf{x}||=1}||\\mathbf{A}\\mathbf{x}||_2 = \\sqrt{\\lambda_\\max}\\tag{Fanshu-1}$$\n",
    "\n",
    "其中 $\\lambda_\\max$ 是矩阵 $\\mathbf{A}^T\\mathbf{A}$ 的最大特征值。\n",
    "\n",
    "**注：证明见冯果忱主编的《数值分析(上册)》的 P25.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "任意矩阵 $\\mathbf{B}\\in R^{n\\times n}$ 的特征值的按模最大值 $\\lambda_\\max(\\mathbf{B})$，称为 $\\mathbf{B}$ 的**谱半径**，记为 $\\rho(\\mathbf{B})$。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "根据谱半径的定义，我们可以重新将(Fanshu-1)记为\n",
    "\n",
    "$$||\\mathbf{A}||_2 = \\sqrt{\\rho(\\mathbf{A}^T\\mathbf{A})}\\tag{Fanshu-2}$$\n",
    "\n",
    "所以 $||\\mathbf{A}||_2$ 也叫做 $\\mathbf{A}$ 的**谱范数**。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "特别地，**当$\\mathbf{A}\\in R^{n\\times n}$ 为对称矩阵时，** $\\mathbf{A}^T\\mathbf{A} = \\mathbf{A}^2$,从而\n",
    "\n",
    "$$||\\mathbf{A}||_2 = \\rho(\\mathbf{A})$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 矩阵的条件数"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "对于线性方程组\n",
    "\n",
    "$$\\mathbf{A}\\mathbf{x}=\\mathbf{b}$$\n",
    "\n",
    "假设它的解存在且唯一，即 $\\mathbf{A}^{-1}$ 存在，下面讨论右端项的误差对解的影响。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "用 $\\mathbf{x}$ 表示方程组的精确解，假设方程组右端存在误差 $\\delta \\mathbf{b}$，对应引起的解的误差为 $\\delta \\mathbf{x}$,则我们有\n",
    "\n",
    "$$\\mathbf{A}(\\mathbf{x}+\\delta \\mathbf{x})=\\mathbf{b} + \\delta \\mathbf{b}$$\n",
    "\n",
    "由此得到误差方程\n",
    "\n",
    "$$\\mathbf{A}\\delta \\mathbf{x}=\\delta \\mathbf{b}$$\n",
    "\n",
    "从而\n",
    "\n",
    "$$||\\delta \\mathbf{x}||\\leq ||\\mathbf{A}^{-1}||\\;||\\delta \\mathbf{b}|| \\tag{Cond-1}$$\n",
    "\n",
    "注意\n",
    "\n",
    "$$||\\mathbf{b}||\\leq ||\\mathbf{A}||\\;||\\mathbf{x}||$$\n",
    "\n",
    "于是由 (Cond-1) 可得到\n",
    "\n",
    "$$\\frac{||\\delta \\mathbf{x}||}{||\\mathbf{x}||}\\leq ||\\mathbf{A}||\\;||\\mathbf{A}^{-1}||\\; ||\\frac{\\delta \\mathbf{b}}{\\mathbf{b}}||$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "上式中的系数 $||\\mathbf{A}||\\;||\\mathbf{A}^{-1}||$ 决定了对误差的敏感程度，称为 $||\\mathbf{A}||$ 的**条件数**，记为\n",
    "\n",
    "$$Cond(\\mathbf{A}) = ||\\mathbf{A}||\\cdot||\\mathbf{A}^{-1}||$$\n",
    "\n",
    "条件数的大小和所取的**范数**有关。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "设 $\\mathbf{A}$ 的特征值为 $|\\lambda_1|\\geq |\\lambda_2|\\geq \\cdots \\geq |\\lambda_n|$>0，当矩阵 $\\mathbf{A}$ 为**对称矩阵**, $\\mathbf{A}$ 和 $\\mathbf{A}^{-1}$ 对应的 **谱范数** 如下：\n",
    "\n",
    "$$||\\mathbf{A}||_2 = \\rho(\\mathbf{A}) = |\\lambda_1| \\quad ||\\mathbf{A}^{-1}||_2 = \\rho(\\mathbf{A}^{-1}) = \\frac{1}{|\\lambda_n|}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "则对称矩阵 $\\mathbf{A}$ 所对应的条件数为\n",
    "\n",
    "$$Cond(\\mathbf{A}) = ||\\mathbf{A}||_2\\cdot||\\mathbf{A}^{-1}||_2 = \\left|\\frac{\\lambda_1}{\\lambda_n}\\right|$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 奇异值分解"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "对于方阵，利用特征值和特征向量可以刻画矩阵的结构，在长方形矩阵情形这些方法不适用，推广的特征值即奇异值分解理论改善了这个状况。利用奇异值和奇异向量不仅可以刻画矩阵本身，还可以进一步刻画线性代数方程组解的结构，是构造性地研究线性代数问题的有力工具。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "**定理** 设 $\\mathbf{A}\\in R^{m\\times n}$, 则存在正交矩阵 $\\mathbf{U} = (\\mathbf{u}_1, \\cdots,\\mathbf{u}_m)\\in R^{m\\times m},\\mathbf{V} = (\\mathbf{v}_1, \\cdots,\\mathbf{v}_n)\\in R^{n\\times n}$ 使\n",
    "\n",
    "$$\\mathbf{U}^T \\mathbf{A}\\mathbf{V}=\n",
    "\\left(                 \n",
    "\\begin{array}{cc}   \n",
    "\\mathbf{\\sum} & \\mathbf{O}\\\\  \n",
    "\\mathbf{O} & \\mathbf{O}\\\\  \n",
    "\\end{array} \n",
    "\\right)$$\n",
    "\n",
    "其中 $\\mathbf{\\sum} = diag(\\sigma_1, \\cdots, \\sigma_r)$，并且 $\\sigma_1\\geq \\sigma_2\\geq\\cdots\\geq \\sigma_r >0$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='figure/SVD.jpg' width='500' height='400' align='left'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "我们记\n",
    "\n",
    "$$\\mathbf{D} = \\left(                 \n",
    "\\begin{array}{cc}   \n",
    "\\mathbf{\\sum} & \\mathbf{O}\\\\  \n",
    "\\mathbf{O} & \\mathbf{O}\\\\  \n",
    "\\end{array} \n",
    "\\right)$$\n",
    "\n",
    "则有 $\\mathbf{U}^T \\mathbf{A}\\mathbf{V}= \\mathbf{D}$, 由 $\\mathbf{U},\\mathbf{V}$ 的正交性质可知\n",
    "\n",
    "$$\\mathbf{A}= \\mathbf{U}\\mathbf{D}\\mathbf{V}^T$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "**推论：** $\\mathbf{V}$ 的列向量是矩阵 $\\mathbf{A}^T\\mathbf{A}$ 的特征向量；$\\mathbf{U}$ 的列向量是矩阵 $\\mathbf{A}\\mathbf{A}^T$ 的特征向量，即\n",
    "\n",
    "$$\\begin{split}\n",
    "\\mathbf{V}^T\\mathbf{A}^T\\mathbf{A}\\mathbf{V} = diag(\\sigma_1^2,\\cdots,\\sigma_r^2,0,\\cdots,0),\\\\\n",
    "\\mathbf{U}^T\\mathbf{A}\\mathbf{A}^T\\mathbf{U} = diag(\\sigma_1^2,\\cdots,\\sigma_r^2,0,\\cdots,0),\n",
    "\\end{split}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们简单证明关于 $\\mathbf{V}$ 的结论，关于 $\\mathbf{U}$ 类似。\n",
    "\n",
    "由 $\\mathbf{U}^T \\mathbf{A}\\mathbf{V}= \\mathbf{D}$ 可知\n",
    "\n",
    "$$\\begin{split}\n",
    "diag(\\sigma_1^2,\\cdots,\\sigma_r^2,0,\\cdots,0) &= \\mathbf{D}^T\\mathbf{D}\\\\\n",
    "&=(\\mathbf{U}^T \\mathbf{A}\\mathbf{V})^T(\\mathbf{U}^T \\mathbf{A}\\mathbf{V})\\\\\n",
    "&=\\mathbf{V}^T\\mathbf{A}^T\\mathbf{U}\\mathbf{U}^T \\mathbf{A}\\mathbf{V}\\\\\n",
    "&=\\mathbf{V}^T\\mathbf{A}^T\\mathbf{A}\\mathbf{V}\n",
    "\\end{split}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "综上所述：\n",
    "* 对角矩阵 $\\mathbf{D}$ 对角线上的元素称为矩阵 $\\mathbf{A}$ 的**奇异值**；\n",
    "* 矩阵 $\\mathbf{U}$ 的列向量称为**左奇异向量**，其列向量为矩阵 $\\mathbf{A}^T\\mathbf{A}$ 的特征向量；\n",
    "* 矩阵 $\\mathbf{V}$ 的列向量称为**右奇异向量**，其列向量为矩阵 $\\mathbf{A}\\mathbf{A}^T$ 的特征向量；\n",
    "* $\\mathbf{A}$ 的非零奇异值为矩阵 $\\mathbf{A}^T\\mathbf{A}$，同时也是 $\\mathbf{A}\\mathbf{A}^T$ 的特征值的平方根。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[奇异值分解(SVD) --- 线性变换几何意义](http://blog.sciencenet.cn/home.php?mod=space&uid=696950&do=blog&quickforward=1&id=699380)\n",
    "\n",
    "[奇异值分解(SVD) --- 几何意义](http://blog.sciencenet.cn/blog-696950-699432.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 上溢和下溢"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "首先我们介绍在进行数值计算时会遇到的三种误差类型：\n",
    "\n",
    "1. **舍入误差**：一个数 $x^\\ast$ 与它经过“舍入”或“切断”产生近似数 x 之间的误差称为 **舍入误差**。\n",
    "\n",
    "\n",
    "2. **截断误差**：许多数学运算（比如微分、积分、无穷级数求和等）是通过极限过程定义的，但在计算机上只能完成有限次的运算。用有限过程近似无穷过程，表现为对无穷过程的截断，由此产生的误差称为 **舍入误差**。\n",
    "\n",
    "\n",
    "3. **传播误差**：许多数值方法是用递归公式的形式给出的，初始数据往往具有误差，每一步计算也要产生舍入误差。这些误差参加运算，要影响后面的计算结果，即这些误差要向后传播，由此产生的误差称为**传播误差**。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "实数在计算机上的表示是通过有限数量的位模式来进行表示，所以会引入不可避免的近似误差。许多情况下，仅仅是舍入误差。\n",
    "\n",
    "一种极具毁灭性的舍入误差是**下溢（underflow）**：当接近零的数被四舍五入为零时会发生下溢。另一种极具破坏力的数值错误形式是**上溢**：当大量级的数被近似为 $\\infty$ 或 $-\\infty$ 时会发生上溢。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "一个必须对上溢和下溢进行稳定的例子是 **softmax 函数**：\n",
    "\n",
    "$$softmax(\\mathbf{x})_i = \\frac{e^{x_i}}{\\sum_{j=1}^n e^{x_i}}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "当所有的 $x_i$ 取值为 c 时，理论上每个输出都应该是 $\\frac{1}{c}$，由\n",
    "$$\\begin{split}\n",
    "& \\lim_{c\\rightarrow +\\infty}e^c = +\\infty\\\\\n",
    "& \\lim_{c\\rightarrow -\\infty}e^c = 0\\\\\n",
    "\\end{split}$$\n",
    "\n",
    "可知，当 c 量级很大时会发生上溢；c 是很小的负数时会发生下溢。softmax 函数的分母会变成 0 。这两个数值计算上不稳定的问题可以通过定义 \n",
    "\n",
    "$$softmax(\\mathbf{z})_i = \\frac{e^{z_i}}{\\sum_{j=1}^n e^{z_j}}$$ \n",
    "\n",
    "其中\n",
    "\n",
    "$$\\mathbf{z} = \\mathbf{x} - \\max_i x_i$$\n",
    "\n",
    "上述的运算是广播机制,这种线性平移映射不会影响或者改变 $softmax(\\mathbf{x})$ 的输出值。\n",
    "\n",
    "减去 $\\max_i x_i$ 使得 \n",
    "\n",
    "$$e^{z_i} \\leq 1$$\n",
    "\n",
    "所以不会发生上溢，同时分母中至少有一个值为 1 的项，不会使得分母为 0 从而发生数值下溢。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 信息论"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 香农熵"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们定义一个事件 x 的自信息为\n",
    "\n",
    "$$I(x) = -\\log P(x)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们可以用**香农熵**来对整个概率分布中的不确定性总量进行量化：\n",
    "\n",
    "$$H(x)=-E_{x\\sim P}\\log P(x)$$\n",
    "\n",
    "也记为 $H(P)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "机器学习中的决策树选择分裂节点的信息增益概念就是以此为基础来定义的。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KL散度"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "如果对于同一个随机变量 x 有两个单独的概率分布 $P(x)$ 和 $Q(x)$，可以使用 **KL散度** 来衡量这两个分布的差异：\n",
    "\n",
    "$$D_{KL}(P||Q) = E_{x\\sim P}\\left[\\log\\frac{P(x)}{Q(x)}\\right]=E_{x\\sim P}[\\log P(x)-\\log Q(x)]$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "KL 散度的性质：\n",
    "\n",
    "* KL 散度是不对称的；\n",
    "* KL 散度是非负的；\n",
    "* KL 散度为0，当且仅当 P 和 Q 在离散型变量的情况下是相同的分布，或者在连续型变量的情况下是“几乎处处”相同的。\n",
    "\n",
    "因为 KL 散度是非负的，并且衡量的是两个分布之间的差异，经常被用作度量两个分布之间的“距离”；然而因为 KL 散度不对称的性质，它并不是真的距离。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [交叉熵](https://zh.wikipedia.org/wiki/%E4%BA%A4%E5%8F%89%E7%86%B5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "和 KL 散度密切联系的量就是**交叉熵(cross-entropy)**:\n",
    "\n",
    "$$ H(P,Q)=H(P)+D_{KL}(P||Q) = -E_{x\\sim P}\\log Q(x)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "由交叉熵的定义可知\n",
    "\n",
    "$$\\min_{Q}H(P,Q) = \\min_{Q}D_{KL}(P||Q)$$"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "473px",
    "left": "114px",
    "top": "141px",
    "width": "213px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
